* JAS refine
  　極性判定が出来るデータを見つけたので、これを自分用に加工します。\\
  　加工基準として、URLなんかは省くようにしています。

* 使い方
** 生データ(単語分割をしていないもの)
   以下を実行します。
  #+begin_src shell
  git clone https://github.com/MokkeMeguru/JAS-refine
  git clone https://github.com/sugiyamath/bert
  cp -r bert/JAS JAS-refine/JAS
  cd JAS-refine
  python parse.py
  #+end_src
  csv 形式のデータ、 *raw_dev.csv* *raw_test.csv* *raw_train.csv* が *JAS-refine* フォルダ下に得られます。\\
  example:
 |---------------+---|
 | "センテンス1" | 1 |
 | "センテンス2" | 1 |
 | "センテンス3" | 2 |
 | "センテンス4" | 1 |
 |---------------+---|
  
  ラベルは 0 から 5 の整数値であり、0 が positive 5 が negative のようです。
* require
  - Python 3
* 生データ(単語分割していないもの)
  - bakup
    - raw-data
      - raw.txt 一行ごとにツイートが入っている生データ
      - raw_dev.csv 
      - raw_test.csv 
      - raw_train.csv dev:test:train=1:1:10 の割合でデータが分割されています。
    - tagged-data
      - retagged-raw.csv 1ツイートごとに極性判定されたデータ
      - retagged-sentence.csv 1ツイートを1文ごとに分解して極性判定されたデータ

* TODO todo
  - [ ] mecab-neologd splitter
  - [ ] sentence-pieces splitter

* Memo
  ./config_secret.yaml の書き方
  #+BEGIN_SRC yaml
GCP:
  API-key: <your-api-key>
# see https://console.developers.google.com/apis/api/language.googleapis.com/
# see https://cloud.google.com/natural-language/docs/common/auth?hl=ja

  #+END_SRC

